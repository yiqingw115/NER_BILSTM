{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "““Untitled2.ipynb”的副本”的副本",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYx8msoAGpyp"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iIzMeq61kpI"
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "velubf6Zk9yG"
      },
      "source": [
        "# lab 10\n",
        "testid = \"1laS3maLWQNNuTTOT-QRxn0fBOaqCMWlk\"\n",
        "trainid = \"19Od31ooLtxt78tUIgMjUgeIojsAZbkiD\"\n",
        "valid = \"1tiWCzJKMTUJf0k_QzoLHErb1VI0IjKC5\"\n",
        "\n",
        "downloaded = drive.CreateFile({'id':testid})\n",
        "downloaded.GetContentFile('test_data.csv')\n",
        "downloaded = drive.CreateFile({'id':trainid})\n",
        "downloaded.GetContentFile('train_data.csv')\n",
        "downloaded = drive.CreateFile({'id':valid})\n",
        "downloaded.GetContentFile('val_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "7tsw-NQbjnUV",
        "outputId": "50b1c836-04ab-47f5-9aac-323219729602"
      },
      "source": [
        "# lab 10\n",
        "# import dataset\n",
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('train_data.csv')\n",
        "df_test = pd.read_csv('test_data.csv')\n",
        "df_val = pd.read_csv('val_data.csv')\n",
        "df_train.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sents</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>On Monday 19 December the UN Security Council ...</td>\n",
              "      <td>O B-Temporal I-Temporal I-Temporal B-Organisat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>Our position remains as strong as ever – we wi...</td>\n",
              "      <td>O O O O O O O O B-Organisation O O O O O O O O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>A Foreign Office spokesman said :</td>\n",
              "      <td>B-Person I-Person I-Person I-Person O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>It was completed in 1956 by the German company...</td>\n",
              "      <td>O O O O B-Temporal O O B-Nationality O B-Organ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>Over the last year the Global Coalition has la...</td>\n",
              "      <td>O B-Temporal I-Temporal I-Temporal B-Organisat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>For now though , Omar says the library is help...</td>\n",
              "      <td>O O O O B-Person O B-Location I-Location O O O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>\" We mourn the loss of one of our own , Navy S...</td>\n",
              "      <td>O B-Organisation O O O O O O O O O B-Person I-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>- Ensure an effective posture .</td>\n",
              "      <td>O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>It ’ s essential that the regime and its backe...</td>\n",
              "      <td>O O O O O B-Organisation I-Organisation O O O ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>The victims included his nephews working in th...</td>\n",
              "      <td>B-Organisation I-Organisation O B-Organisation...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 sents                                             labels\n",
              "415  On Monday 19 December the UN Security Council ...  O B-Temporal I-Temporal I-Temporal B-Organisat...\n",
              "533  Our position remains as strong as ever – we wi...  O O O O O O O O B-Organisation O O O O O O O O...\n",
              "226                  A Foreign Office spokesman said :            B-Person I-Person I-Person I-Person O O\n",
              "265  It was completed in 1956 by the German company...  O O O O B-Temporal O O B-Nationality O B-Organ...\n",
              "328  Over the last year the Global Coalition has la...  O B-Temporal I-Temporal I-Temporal B-Organisat...\n",
              "332  For now though , Omar says the library is help...  O O O O B-Person O B-Location I-Location O O O...\n",
              "257  \" We mourn the loss of one of our own , Navy S...  O B-Organisation O O O O O O O O O B-Person I-...\n",
              "73                     - Ensure an effective posture .                                        O O O O O O\n",
              "343  It ’ s essential that the regime and its backe...  O O O O O B-Organisation I-Organisation O O O ...\n",
              "259  The victims included his nephews working in th...  B-Organisation I-Organisation O B-Organisation..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Uv1Ldp3GlhX_",
        "outputId": "f1d5f73d-0894-4501-d65e-b84086642bb5"
      },
      "source": [
        "df_train.sents[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Operation Steel Curtain ( Arabic : ا ل ح ج ا ب ا ل ف و ل ا ذ ي Al Hejab Elfulathi ) was a military operation executed by coalition forces in early November 2005 to reduce the flow of foreign insurgents crossing the border and joining the Iraqi insurgency .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5aedDjPvkiU"
      },
      "source": [
        "def get_tokens(dataframe):\n",
        "\n",
        "  sentences = list(dataframe.sents)\n",
        "\n",
        "  tokenized_sentences = []\n",
        "  for sentence in sentences:\n",
        "    tokens = sentence.split(\" \")\n",
        "    tokens_lower = [s.lower() for s in tokens]\n",
        "    tokenized_sentences.append(tokens_lower)\n",
        "\n",
        "  return tokenized_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWtro_lFyN8g"
      },
      "source": [
        "def get_labels(dataframe):\n",
        "\n",
        "  labels = list(dataframe.labels)\n",
        "\n",
        "  target_y = []\n",
        "  for label in labels:\n",
        "    target_y.append(label.split(\" \"))\n",
        "\n",
        "  return target_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf8Qa5WkwAHl"
      },
      "source": [
        "train_data = get_tokens(df_train)\n",
        "target_y_train = get_labels(df_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf-rW-ir0jsG"
      },
      "source": [
        "validation_data = get_tokens(df_val)\n",
        "target_y_validation = get_labels(df_val) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TLqNGpj0jzW"
      },
      "source": [
        "test_data = get_tokens(df_test)\n",
        "# target_y_test = get_labels(df_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNPKE28iwbY_"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta8YhhkvwiU-"
      },
      "source": [
        "target_y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjIwy-xIHoLi"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClWb48Rp0dDW"
      },
      "source": [
        "Generate word_to_ix and tag_to_ix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ5R_m6_o69b"
      },
      "source": [
        "# lab 9\n",
        "word_to_ix = {}\n",
        "for sentence in train_data+validation_data+test_data:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in target_y_train+target_y_validation:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_Dy1wonpPTb"
      },
      "source": [
        "POS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo9WA92W1DOz"
      },
      "source": [
        "tokens = train_data+validation_data+test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV30ZPRk0BqR",
        "outputId": "d7e08336-1381-42e6-f598-4c1aaa06c1d2"
      },
      "source": [
        "# https://blog.csdn.net/JasonJarvan/article/details/79955664?ops_request_misc=&request_id=&biz_id=102&utm_term=python%20pos%20tag%E7%94%9F%E6%88%90&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-.pc_search_result_control_group&spm=1018.2226.3001.4187\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "tags_pos = []\n",
        "for scentence in tokens:\n",
        "  pos_tags =nltk.pos_tag(scentence)\n",
        "  ret = []\n",
        "  for word,pos in pos_tags:\n",
        "    ret.append(pos)\n",
        "  tags_pos.append(ret)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k75azIbJ30AH"
      },
      "source": [
        "tags_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElleVYHN4xZQ"
      },
      "source": [
        "dependency path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dK-_eBw5zqM"
      },
      "source": [
        "# lab7\n",
        "import spacy\n",
        "#PrettyTable is a Python library for generating simple ASCII tables.\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "dependency_path = []\n",
        "\n",
        "for sentence in tokens:\n",
        "  # covert list to string\n",
        "  \n",
        "  parse = nlp(''.join(sentence))\n",
        "  temp = []\n",
        "  for token in parse:\n",
        "    temp.append(token.dep_)\n",
        "  dependency_path.append(temp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4_k1bWU8BR5"
      },
      "source": [
        "dependency_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBycXate8Hao"
      },
      "source": [
        "Embedding pos tag and dependency path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euAE26gg8Gop"
      },
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "word_emb_model_pos = FastText(sentences = tags_pos, size=25, word_ngrams=5, window=5, min_count=1, workers=2, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOnM7I459i-B",
        "outputId": "37ec4e3f-12c6-458a-c556-8711a2631b61"
      },
      "source": [
        "embedding_pos={}\n",
        "for i in range(len(tokens)):\n",
        "    for j in range(len(tokens[i])):\n",
        "        embedding_pos[tokens[i][j]] = word_emb_model_pos[tags_pos[i][j]]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KT65d04_K36"
      },
      "source": [
        "embedding_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdZ_kjpq8G0B"
      },
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "word_emb_model_dp = FastText(sentences = dependency_path, size=25, word_ngrams=5, window=5, min_count=1, workers=2, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xql5jvK_FcP",
        "outputId": "0e123f11-37bc-4872-8f7d-ed1c14d08aa9"
      },
      "source": [
        "embedding_dp={}\n",
        "for i in range(len(tokens)):\n",
        "    for j in range(len(tokens[i])):\n",
        "      try:\n",
        "        embedding_dp[tokens[i][j]] = word_emb_model_dp[dependency_path[i][j]]\n",
        "      except:\n",
        "        continue\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFLkQfjAAVI3"
      },
      "source": [
        "embedding_dp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARnn1hBYJG44"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHmTkFCX_Jq-",
        "outputId": "2ab50ab9-5b16-4d1f-f90b-01f1079173e5"
      },
      "source": [
        "# baseline\n",
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-twitter-25\") \n",
        "\n",
        "EMBEDDING_DIM = 25\n",
        "\n",
        "embedding_matrix_base = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix_base.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        embedding_matrix_base.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix_base = np.array(embedding_matrix_base)\n",
        "embedding_matrix_base.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3957, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDS2oa3KPSiW"
      },
      "source": [
        "convert dataset into idxs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0xxJjrHPRQu"
      },
      "source": [
        "# lab 9\n",
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_data,word_to_ix)\n",
        "train_output_index = to_index(target_y_train,tag_to_ix)\n",
        "val_input_index = to_index(validation_data,word_to_ix)\n",
        "val_output_index = to_index(target_y_validation,tag_to_ix)\n",
        "test_input_index = to_index(test_data,word_to_ix)\n",
        "# test_output_index = to_index(target_y_test,tag_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yYxz7yf_Jy3"
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF_base(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF_base, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix_base))\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8Sx9Fhj_J5t"
      },
      "source": [
        "import numpy as np\n",
        "def cal_acc(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    return predicted, ground_truth, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nTsZuv-_J8F"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 50\n",
        "\n",
        "model = BiLSTM_CRF_base(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFyc1DIR_J_c",
        "outputId": "04ba1d79-c93e-42e2-a800-e7a7a266030d"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(10):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 15010.89, train acc: 0.7463, val loss: 4735.04, val acc: 0.6953, time: 84.81s\n",
            "Epoch:2, Training loss: 9081.21, train acc: 0.7930, val loss: 3678.69, val acc: 0.7404, time: 84.88s\n",
            "Epoch:3, Training loss: 6968.59, train acc: 0.8134, val loss: 3255.39, val acc: 0.7569, time: 84.73s\n",
            "Epoch:4, Training loss: 5871.36, train acc: 0.8269, val loss: 2957.17, val acc: 0.7719, time: 84.76s\n",
            "Epoch:5, Training loss: 5119.91, train acc: 0.8409, val loss: 2702.64, val acc: 0.7802, time: 85.01s\n",
            "Epoch:6, Training loss: 4519.54, train acc: 0.8538, val loss: 2546.33, val acc: 0.7846, time: 84.76s\n",
            "Epoch:7, Training loss: 4069.54, train acc: 0.8626, val loss: 2392.62, val acc: 0.7911, time: 84.65s\n",
            "Epoch:8, Training loss: 3687.21, train acc: 0.8754, val loss: 2255.28, val acc: 0.7947, time: 85.40s\n",
            "Epoch:9, Training loss: 3357.28, train acc: 0.8834, val loss: 2229.22, val acc: 0.7973, time: 84.82s\n",
            "Epoch:10, Training loss: 3062.14, train acc: 0.8954, val loss: 2139.57, val acc: 0.8013, time: 84.79s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2as7bBzEWyO"
      },
      "source": [
        "torch.save(model, \"ass2_1.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UV9LKAy_KCZ"
      },
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "y_pred, y_true, _ = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fc34nsN_KFK"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crlej0EJA-4Y"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_sequence = []\n",
        "f1_score_num_1 = f1_score(y_true_decode,y_pred_decode,average='weighted')\n",
        "f1_sequence.append(f1_score_num_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goU2onABE0Ui",
        "outputId": "7040f702-463a-4c63-829d-1f492e621154"
      },
      "source": [
        "f1_score_num_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7814615945746894"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOZhM-3JrYgR",
        "outputId": "fffdbac7-cd08-49f6-ecfd-757106c1960c"
      },
      "source": [
        "f1_sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7814615945746894]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L480xDMOzeZ"
      },
      "source": [
        "# NER model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1YNsrIT1H05"
      },
      "source": [
        "Generate Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIyNhbF5O30v",
        "outputId": "c537bb9a-eafa-4b08-a8ed-426c4f1e4644"
      },
      "source": [
        "#lab 9\n",
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "word_emb_model = api.load(\"glove-twitter-100\") \n",
        "\n",
        "EMBEDDING_DIM = 150\n",
        "\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    word_embedding_token = []\n",
        "    try:\n",
        "        word_embedding_token.extend(word_emb_model.wv[word])\n",
        "        word_embedding_token.extend(embedding_pos[word])\n",
        "        word_embedding_token.extend(embedding_dp[word])\n",
        "        embedding_matrix.append(word_embedding_token)\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3957, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMCIjFz4CWXX"
      },
      "source": [
        "embedding_matrix[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbXWI-LD1RV-"
      },
      "source": [
        "convert dataset into idxs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuBe8P72wRsK"
      },
      "source": [
        "def cosine_similarity(vector1, vector2):\n",
        "  dot_product = 0.0\n",
        "  normA = 0.0\n",
        "  normB = 0.0\n",
        "  for a, b in zip(vector1, vector2):\n",
        "    dot_product += a * b\n",
        "    normA += a ** 2\n",
        "    normB += b ** 2\n",
        "  if normA == 0.0 or normB == 0.0:\n",
        "    return 0\n",
        "  else:\n",
        "    return round(dot_product / ((normA**0.5)*(normB**0.5)) * 100, 2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-uTqwnP2zSh"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMT8AeeVpMPi"
      },
      "source": [
        "# lab 9\n",
        "import math\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, layers, attention_method = None):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "\n",
        "        # stacked layer\n",
        "        self.layers = layers\n",
        "        # attention method\n",
        "        self.attention_method = attention_method\n",
        "       \n",
        "\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        \n",
        "        # find the optimal number of stacked layers\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2*self.layers, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2*self.layers, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def cal_attention(self, hidden, encoder_hiddens, attention_method):\n",
        "        if method == \"Dot Product\":\n",
        "            # bmm: https://pytorch.org/docs/master/generated/torch.bmm.html\n",
        "            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "\n",
        "        elif method == \"Scale Dot Product\":\n",
        "            # COMPLETE THIS PART - Scale Dot Product calculation method\n",
        "            attn_weights = F.softmax(1/np.sqrt(self.hidden_size)*torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "\n",
        "        elif method == \"Content-base\":\n",
        "            # COMPLETE THIS PART - Scale Dot Product calculation method\n",
        "            attn_weights = F.softmax(cosine_similarity(hidden, encoder_hiddens.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "\n",
        "\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0CL2z0nvnHP"
      },
      "source": [
        "# lab 9\n",
        "import math\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "# Bi-LSTM without CRF\n",
        "class BiLSTM_without_CRF(nn.Module):\n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, layers, attention_method = None):\n",
        "        super(BiLSTM_without_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "\n",
        "        # stacked layer\n",
        "        self.layers = layers\n",
        "        # attention method\n",
        "        self.attention_method = attention_method\n",
        "\n",
        "\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        \n",
        "        # find the optimal number of stacked layers\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2*self.layers, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2*self.layers, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def cal_attention(self, hidden, encoder_hiddens, attention_method):\n",
        "        if method == \"Dot Product\":\n",
        "            # bmm: https://pytorch.org/docs/master/generated/torch.bmm.html\n",
        "            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "\n",
        "        elif method == \"Scale Dot Product\":\n",
        "            # Scale Dot Product calculation method\n",
        "            attn_weights = F.softmax(1/np.sqrt(self.hidden_size)*torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "\n",
        "        elif method == \"Content-base\":\n",
        "            # Content-base calculation method\n",
        "            attn_weights = F.softmax(cosine_similarity(hidden, encoder_hiddens.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        \n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "        return lstm_feats, torch.argmax(lstm_feats, -1)\n",
        "        # lstm_feats, tags = model(sentence_in)\n",
        "        # loss = loss_func(lstm_feats, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snKRrToTvpme"
      },
      "source": [
        "Function for accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzwpmDb5Ya8T"
      },
      "source": [
        "import numpy as np\n",
        "def cal_acc(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    return predicted, ground_truth, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ivpIXKPQk-O"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXehvtIsJN5R"
      },
      "source": [
        "# Model 2 - attention - Dot product, stacked layer - 1, crf - with crf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bV_3w_NvwjK"
      },
      "source": [
        "Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5vRCnp2YuNo"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 150\n",
        "\n",
        "\n",
        "# attention - Dot Product, stacked layer - 1, crf - use\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers = 1, \n",
        "                   attention_method = \"Dot Product\").to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, weight_decay=1e-4)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRD0qlCv2Jb"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amRMsqkWY1oG"
      },
      "source": [
        "train_data=train_input_index+val_input_index\n",
        "train_label=train_output_index+val_output_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1YDBiywY8EG",
        "outputId": "6c2956b2-fd94-4322-d5a7-174b43508468"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(10):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 13276.36, train acc: 0.7736, val loss: 4025.32, val acc: 0.7294, time: 87.72s\n",
            "Epoch:2, Training loss: 7683.94, train acc: 0.8141, val loss: 3180.44, val acc: 0.7613, time: 87.66s\n",
            "Epoch:3, Training loss: 5848.81, train acc: 0.8436, val loss: 2785.30, val acc: 0.7829, time: 87.72s\n",
            "Epoch:4, Training loss: 4654.94, train acc: 0.8737, val loss: 2557.29, val acc: 0.7975, time: 87.79s\n",
            "Epoch:5, Training loss: 3737.52, train acc: 0.8960, val loss: 2534.88, val acc: 0.8024, time: 87.83s\n",
            "Epoch:6, Training loss: 3053.47, train acc: 0.9100, val loss: 2599.05, val acc: 0.7986, time: 87.88s\n",
            "Epoch:7, Training loss: 2508.40, train acc: 0.9245, val loss: 2607.92, val acc: 0.7984, time: 88.01s\n",
            "Epoch:8, Training loss: 2107.10, train acc: 0.9413, val loss: 2599.02, val acc: 0.8034, time: 87.94s\n",
            "Epoch:9, Training loss: 1798.22, train acc: 0.9477, val loss: 2772.83, val acc: 0.8009, time: 88.50s\n",
            "Epoch:10, Training loss: 1536.85, train acc: 0.9501, val loss: 2860.31, val acc: 0.7903, time: 88.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT4UsoSaei-s"
      },
      "source": [
        "torch.save(model, \"ass2_2.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqrn3vApwul3"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isrjLlWewtjv"
      },
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "y_pred, y_true, _ = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ8rqSpMww63"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true_decode,y_pred_decode,digits=4))\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W66UUiRhLanV"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "f1_score_num_2 = f1_score(y_true_decode,y_pred_decode,average='weighted')\n",
        "f1_sequence.append(f1_score_num_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tmLVCFQeagd",
        "outputId": "c8d5e525-41c4-4794-e87e-8b2a2ee39eeb"
      },
      "source": [
        "f1_score_num_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7715082808132664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pMwg5BlxPck",
        "outputId": "bc3aff74-c35e-4197-c152-0f194848a68d"
      },
      "source": [
        "f1_sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7814615945746894, 0.7715082808132664]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZEa-U2qJq81"
      },
      "source": [
        "# Model 3 - attention - Dot product, stacked layer - 2, crf - with crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypdIa9M4Kfp-"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 150\n",
        "\n",
        "\n",
        "# attention - Dot Product, stacked layer - 1, crf - use\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers = 2, \n",
        "                   attention_method = \"Dot Product\").to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, weight_decay=1e-4)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWxWUjoyKvY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d138a577-a62e-4c3a-8a6e-a2084f575ba0"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(10):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 13726.23, train acc: 0.7419, val loss: 4490.61, val acc: 0.6966, time: 96.71s\n",
            "Epoch:2, Training loss: 9103.29, train acc: 0.7895, val loss: 3460.41, val acc: 0.7442, time: 96.68s\n",
            "Epoch:3, Training loss: 6774.53, train acc: 0.8254, val loss: 2937.06, val acc: 0.7702, time: 96.54s\n",
            "Epoch:4, Training loss: 5386.70, train acc: 0.8563, val loss: 2638.79, val acc: 0.7861, time: 96.75s\n",
            "Epoch:5, Training loss: 4277.58, train acc: 0.8748, val loss: 2570.23, val acc: 0.7977, time: 96.77s\n",
            "Epoch:6, Training loss: 3494.65, train acc: 0.8905, val loss: 2588.74, val acc: 0.7990, time: 96.56s\n",
            "Epoch:7, Training loss: 2956.94, train acc: 0.9054, val loss: 2642.56, val acc: 0.7958, time: 96.64s\n",
            "Epoch:8, Training loss: 2521.38, train acc: 0.9127, val loss: 2750.31, val acc: 0.7981, time: 96.63s\n",
            "Epoch:9, Training loss: 2062.29, train acc: 0.9357, val loss: 2810.54, val acc: 0.7988, time: 96.60s\n",
            "Epoch:10, Training loss: 1763.83, train acc: 0.9337, val loss: 3057.58, val acc: 0.8028, time: 96.72s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKWrSDfqjYy4"
      },
      "source": [
        "torch.save(model, \"ass2_3.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlbW1-SEK2hQ"
      },
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "y_pred, y_true, _ = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPa3iBfnK_Rq"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "f1_score_num_3 = f1_score(y_true_decode,y_pred_decode,average='weighted')\n",
        "f1_sequence.append(f1_score_num_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qHCUzap1Yr-",
        "outputId": "c2b66690-e516-4381-f3ac-1f409abc3daf"
      },
      "source": [
        "f1_sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7814615945746894, 0.7715082808132664, 0.7788268436176835]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAPGnmjwNJcK"
      },
      "source": [
        "# Model 4 - attention - Dot product, stacked layer - 3, crf - with crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R1ct-IsNS8D"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 150\n",
        "\n",
        "\n",
        "# attention - Dot Product, stacked layer - 1, crf - use\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers = 3, \n",
        "                   attention_method = \"Dot Product\").to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, weight_decay=1e-4)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32dOXmH9NTAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6514fbc-17e9-46d1-e045-7a667ef7c01b"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(10):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 16761.34, train acc: 0.6999, val loss: 5535.29, val acc: 0.6485, time: 105.70s\n",
            "Epoch:2, Training loss: 12354.61, train acc: 0.7363, val loss: 4388.86, val acc: 0.6907, time: 105.50s\n",
            "Epoch:3, Training loss: 9507.23, train acc: 0.7721, val loss: 3602.12, val acc: 0.7215, time: 105.52s\n",
            "Epoch:4, Training loss: 7507.93, train acc: 0.8084, val loss: 3092.28, val acc: 0.7531, time: 105.52s\n",
            "Epoch:5, Training loss: 5980.63, train acc: 0.8447, val loss: 2814.10, val acc: 0.7719, time: 105.50s\n",
            "Epoch:6, Training loss: 4869.70, train acc: 0.8617, val loss: 2641.50, val acc: 0.7831, time: 105.55s\n",
            "Epoch:7, Training loss: 4074.18, train acc: 0.8772, val loss: 2657.44, val acc: 0.7812, time: 105.55s\n",
            "Epoch:8, Training loss: 3471.77, train acc: 0.8867, val loss: 2705.31, val acc: 0.7884, time: 105.43s\n",
            "Epoch:9, Training loss: 2967.63, train acc: 0.8978, val loss: 2789.51, val acc: 0.7911, time: 105.45s\n",
            "Epoch:10, Training loss: 2546.70, train acc: 0.9152, val loss: 2874.91, val acc: 0.7907, time: 105.62s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDjOB13Np8mR"
      },
      "source": [
        "torch.save(model, \"ass2_4.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SaCDG8Jp8xU"
      },
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "y_pred, y_true, _ = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6PDS4KNNTFt"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "f1_score_num_4 = f1_score(y_true_decode,y_pred_decode,average='weighted')\n",
        "f1_sequence.append(f1_score_num_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZrSnDxF57CL"
      },
      "source": [
        "f1_sequence = []\n",
        "f1_sequence.append(f1_score_num_1)\n",
        "f1_sequence.append(f1_score_num_2)\n",
        "f1_sequence.append(f1_score_num_3)\n",
        "f1_sequence.append(f1_score_num_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX6RLuD56OC6",
        "outputId": "6858d95d-ac01-4ff7-f283-adaa6b8b8990"
      },
      "source": [
        "f1_sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7814615945746894,\n",
              " 0.7715082808132664,\n",
              " 0.7788268436176835,\n",
              " 0.7632831368650179]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GPFPHvslOoN"
      },
      "source": [
        "# Model 5 - attention - Scale Dot Product, stacked layer - 1, crf - with crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-eAbO39ljYQ"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 150\n",
        "\n",
        "\n",
        "# attention - Dot Product, stacked layer - 1, crf - use\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers = 1, \n",
        "                   attention_method = \"Scale Dot Product\").to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, weight_decay=1e-4)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrKyBUu_ljhr",
        "outputId": "e47a49c5-73b6-4203-9b2c-f00287a6e142"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(10):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 14120.08, train acc: 0.7780, val loss: 4158.22, val acc: 0.7296, time: 87.82s\n",
            "Epoch:2, Training loss: 7950.26, train acc: 0.8177, val loss: 3287.44, val acc: 0.7598, time: 88.08s\n",
            "Epoch:3, Training loss: 5993.37, train acc: 0.8481, val loss: 2864.88, val acc: 0.7856, time: 87.83s\n",
            "Epoch:4, Training loss: 4722.36, train acc: 0.8736, val loss: 2694.91, val acc: 0.7971, time: 87.83s\n",
            "Epoch:5, Training loss: 3772.40, train acc: 0.8929, val loss: 2709.77, val acc: 0.7983, time: 87.83s\n",
            "Epoch:6, Training loss: 3055.07, train acc: 0.9105, val loss: 2664.33, val acc: 0.7996, time: 87.87s\n",
            "Epoch:7, Training loss: 2559.94, train acc: 0.9235, val loss: 2833.25, val acc: 0.8011, time: 87.92s\n",
            "Epoch:8, Training loss: 2180.34, train acc: 0.9328, val loss: 2826.57, val acc: 0.8045, time: 87.96s\n",
            "Epoch:9, Training loss: 1837.77, train acc: 0.9435, val loss: 2857.68, val acc: 0.8036, time: 87.75s\n",
            "Epoch:10, Training loss: 1542.28, train acc: 0.9448, val loss: 3089.64, val acc: 0.7981, time: 87.97s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBByyuS-p3bl"
      },
      "source": [
        "torch.save(model, \"ass2_5.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og54jLzXp5HO"
      },
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "y_pred, y_true, _ = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hd_Mk6nljqf"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "f1_score_num_5 = f1_score(y_true_decode,y_pred_decode,average='weighted')\n",
        "f1_sequence.append(f1_score_num_5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXDmofqK92ZO",
        "outputId": "1238a65c-a2f5-404c-83a4-66d02ee19b3a"
      },
      "source": [
        "f1_sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7814615945746894,\n",
              " 0.7715082808132664,\n",
              " 0.7788268436176835,\n",
              " 0.7632831368650179,\n",
              " 0.7795319620211295]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs9geppjl3fm"
      },
      "source": [
        "# Model 6 - attention - Content base, stacked layer - 1, crf - with crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xoLlrf-mZXe"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 150\n",
        "\n",
        "\n",
        "# attention - Dot Product, stacked layer - 1, crf - use\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers = 1, \n",
        "                   attention_method = \"Content-base\").to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, weight_decay=1e-4)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntuUWGeamGHG",
        "outputId": "b8567fd4-df45-4afe-da51-c9629fe6a5b5"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(10):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 14129.65, train acc: 0.7761, val loss: 3999.46, val acc: 0.7262, time: 88.02s\n",
            "Epoch:2, Training loss: 7871.76, train acc: 0.8173, val loss: 3126.08, val acc: 0.7596, time: 88.07s\n",
            "Epoch:3, Training loss: 5888.96, train acc: 0.8521, val loss: 2708.05, val acc: 0.7865, time: 88.11s\n",
            "Epoch:4, Training loss: 4620.42, train acc: 0.8749, val loss: 2551.46, val acc: 0.7892, time: 88.10s\n",
            "Epoch:5, Training loss: 3685.49, train acc: 0.8992, val loss: 2493.61, val acc: 0.7945, time: 89.09s\n",
            "Epoch:6, Training loss: 2991.31, train acc: 0.9135, val loss: 2596.91, val acc: 0.7994, time: 88.08s\n",
            "Epoch:7, Training loss: 2516.97, train acc: 0.9288, val loss: 2567.04, val acc: 0.8034, time: 88.23s\n",
            "Epoch:8, Training loss: 2093.35, train acc: 0.9380, val loss: 2649.52, val acc: 0.8026, time: 88.11s\n",
            "Epoch:9, Training loss: 1765.92, train acc: 0.9435, val loss: 2867.71, val acc: 0.8011, time: 88.03s\n",
            "Epoch:10, Training loss: 1563.12, train acc: 0.9522, val loss: 2823.85, val acc: 0.8024, time: 88.07s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmFloD0wpvA9"
      },
      "source": [
        "torch.save(model, \"ass2_6.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTNtb_8bpvqv"
      },
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "y_pred, y_true, _ = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "def decode_output(output_list):\n",
        "    ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJaN2lpnmGQJ"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "f1_score_num_6 = f1_score(y_true_decode,y_pred_decode,average='weighted')\n",
        "f1_sequence.append(f1_score_num_6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0q8oQ-ZBguO"
      },
      "source": [
        "f1_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNMa6PRqpNNs"
      },
      "source": [
        "# Model 7 - attention - Dot Product, stacked layer - 1, crf - without crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW4_wbNmpUZW"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 150\n",
        "\n",
        "\n",
        "# attention - Dot Product, stacked layer - 1, crf - use\n",
        "model = BiLSTM_without_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, layers = 1, \n",
        "                   attention_method = \"Dot Product\").to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, weight_decay=1e-4)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnXoLTWopX8D",
        "outputId": "ed11c677-cf4e-4c2e-88ba-022818138312"
      },
      "source": [
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "\n",
        "import datetime\n",
        "\n",
        "for epoch in range(10):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        lstm_feats, tags = model(sentence_in)\n",
        "        loss = loss_func(lstm_feats, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    # val_loss = 0\n",
        "    # for i, idxs in enumerate(val_input_index):\n",
        "    #     tags_index = val_output_index[i]\n",
        "    #     sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "    #     targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "    #     loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "    #     val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "# The log below is the sample output for this section"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 854.24, train acc: 0.6999, val loss: 3036.80, val acc: 0.6485, time: 9.22s\n",
            "Epoch:2, Training loss: 716.03, train acc: 0.6998, val loss: 3036.80, val acc: 0.6485, time: 9.25s\n",
            "Epoch:3, Training loss: 679.89, train acc: 0.7017, val loss: 3036.80, val acc: 0.6511, time: 9.30s\n",
            "Epoch:4, Training loss: 655.68, train acc: 0.7130, val loss: 3036.80, val acc: 0.6608, time: 9.27s\n",
            "Epoch:5, Training loss: 635.98, train acc: 0.7178, val loss: 3036.80, val acc: 0.6653, time: 9.29s\n",
            "Epoch:6, Training loss: 615.39, train acc: 0.7207, val loss: 3036.80, val acc: 0.6705, time: 9.30s\n",
            "Epoch:7, Training loss: 596.40, train acc: 0.7247, val loss: 3036.80, val acc: 0.6773, time: 9.33s\n",
            "Epoch:8, Training loss: 581.22, train acc: 0.7299, val loss: 3036.80, val acc: 0.6830, time: 9.28s\n",
            "Epoch:9, Training loss: 565.51, train acc: 0.7360, val loss: 3036.80, val acc: 0.6898, time: 9.31s\n",
            "Epoch:10, Training loss: 545.96, train acc: 0.7416, val loss: 3036.80, val acc: 0.6928, time: 9.26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4v85Gt8pbzH"
      },
      "source": [
        "torch.save(model, \"ass2_7.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rhfp7x7pb36"
      },
      "source": [
        "# Call the cal_acc functions you implemented as required\n",
        "y_pred, y_true, _ = cal_acc(model,val_input_index,val_output_index)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfPQ6UdEL6jQ"
      },
      "source": [
        "y_pred_1 = []\n",
        "for item in y_pred:\n",
        "  # tensor(2).item()\n",
        "  item = item.item()\n",
        "  y_pred_1.append(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmEiaLX8NAGU"
      },
      "source": [
        "y_pred_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DPfBEe6LGax"
      },
      "source": [
        "ix_to_tag = {idx : tag for tag, idx in tag_to_ix.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygjE17dBLCRL"
      },
      "source": [
        "def decode_output(output_list):\n",
        "    \n",
        "    return [ix_to_tag[output] for output in output_list]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y96qNutRLUoM"
      },
      "source": [
        "y_true_decode = decode_output(y_true)\n",
        "y_pred_decode = decode_output(y_pred_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ON4BKplpkV5"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "f1_score_num_7 = f1_score(y_true_decode,y_pred_decode,average='weighted')\n",
        "f1_sequence.append(f1_score_num_7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4yC10V6pkf8",
        "outputId": "947bb697-fc91-40d6-b986-5e8077657fce"
      },
      "source": [
        "f1_sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7814615945746894,\n",
              " 0.7715082808132664,\n",
              " 0.7788268436176835,\n",
              " 0.7632831368650179,\n",
              " 0.7795319620211295,\n",
              " 0.7891339927713741,\n",
              " 0.604936071899939]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi6VccIZhflt"
      },
      "source": [
        "# Draw the table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfKU6DMD__gM"
      },
      "source": [
        "Performance Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGXAXnD5wEug",
        "outputId": "bc6453d6-25f5-42aa-9f3c-996d56b286df"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Model', 'Attention method', 'Stacked layers', 'with/without CRF', 'F1 Score'])\n",
        "t.add_row(['base model', 'without attention', '1', 'with CRF', f1_sequence[0]])\n",
        "t.add_row(['Model_2', 'Dot Product', '1', 'with CRF', f1_sequence[1]])\n",
        "t.add_row(['Model_3', 'Dot Product', '2', 'with CRF', f1_sequence[2]])\n",
        "t.add_row(['Model_4', 'Dot Product', '3', 'with CRF', f1_sequence[3]])\n",
        "t.add_row(['Model_5', 'Scaled Dot Product', '1', 'with CRF', f1_sequence[4]])\n",
        "t.add_row(['Model_6', 'Content Base', '1', 'with CRF', f1_sequence[5]])\n",
        "t.add_row(['Model_7', 'Dot Product', '1', 'without CRF', f1_sequence[6]])\n",
        "\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-------------------+----------------+------------------+--------------------+\n",
            "|   Model    |  Attention method | Stacked layers | with/without CRF |      F1 Score      |\n",
            "+------------+-------------------+----------------+------------------+--------------------+\n",
            "| base model | without attention |       1        |     with CRF     | 0.7814615945746894 |\n",
            "|  Model_2   |    Dot Product    |       1        |     with CRF     | 0.7715082808132664 |\n",
            "|  Model_3   |    Dot Product    |       2        |     with CRF     | 0.7788268436176835 |\n",
            "|  Model_4   |    Dot Product    |       3        |     with CRF     | 0.7632831368650179 |\n",
            "|  Model_5   | Scale Dot Product |       1        |     with CRF     | 0.7795319620211295 |\n",
            "|  Model_6   |    Content Base   |       1        |     with CRF     | 0.7891339927713741 |\n",
            "|  Model_7   |    Dot Product    |       1        |   without CRF    | 0.604936071899939  |\n",
            "+------------+-------------------+----------------+------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNoF6N81q-vc"
      },
      "source": [
        "Different input embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMJTK0WYhlv7",
        "outputId": "ffaabfd9-5b9e-4173-f1e1-f210d3fae5b4"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "t = PrettyTable(['Model', 'F1 Score'])\n",
        "t.add_row(['base model', f1_sequence[0]])\n",
        "t.add_row(['base model+pos+dependency prase', f1_sequence[1]])\n",
        "\n",
        "\n",
        "\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------------------+--------------------+\n",
            "|              Model              |      F1 Score      |\n",
            "+---------------------------------+--------------------+\n",
            "|            base model           | 0.7814615945746894 |\n",
            "| base model+pos+dependency prase | 0.7715082808132664 |\n",
            "+---------------------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWoW3RPIrDpG"
      },
      "source": [
        "Different stacked layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y66KHTC8rPAF",
        "outputId": "dc81b1fe-2742-4e78-b1aa-f98b97b6c69e"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Model', 'Stacked layers', 'F1 Score'])\n",
        "t.add_row(['base model', '1', f1_sequence[0]])\n",
        "t.add_row(['Model_2', '1', f1_sequence[1]])\n",
        "t.add_row(['Model_3', '2', f1_sequence[2]])\n",
        "t.add_row(['Model_4', '3', f1_sequence[3]])\n",
        "\n",
        "\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+----------------+--------------------+\n",
            "|   Model    | Stacked layers |      F1 Score      |\n",
            "+------------+----------------+--------------------+\n",
            "| base model |       1        | 0.7814615945746894 |\n",
            "|  Model_2   |       1        | 0.7715082808132664 |\n",
            "|  Model_3   |       2        | 0.7788268436176835 |\n",
            "|  Model_4   |       3        | 0.7632831368650179 |\n",
            "+------------+----------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqlj-ir_uktd"
      },
      "source": [
        "Different attention method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAi-cDhYupkI",
        "outputId": "bee2a841-1dfd-4174-9eb4-c8fce1f63e48"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Model', 'Attention method', 'F1 Score'])\n",
        "t.add_row(['base model', 'without attention', f1_sequence[0]])\n",
        "t.add_row(['Model_2', 'Dot Product', f1_sequence[1]])\n",
        "t.add_row(['Model_5', 'Scale Dot Product', f1_sequence[4]])\n",
        "t.add_row(['Model_6', 'Content Base', f1_sequence[5]])\n",
        "\n",
        "\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-------------------+--------------------+\n",
            "|   Model    |  Attention method |      F1 Score      |\n",
            "+------------+-------------------+--------------------+\n",
            "| base model | without attention | 0.7814615945746894 |\n",
            "|  Model_2   |    Dot Product    | 0.7715082808132664 |\n",
            "|  Model_5   | Scale Dot Product | 0.7795319620211295 |\n",
            "|  Model_6   |    Content Base   | 0.7891339927713741 |\n",
            "+------------+-------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7XdJYsbu7h_"
      },
      "source": [
        "with/without CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrnV8v51u-Od",
        "outputId": "4ee22be3-50b6-4874-a699-852bb64f05da"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Model', 'with/without CRF', 'F1 Score'])\n",
        "t.add_row(['base model', 'with CRF', f1_sequence[0]])\n",
        "t.add_row(['Model_2', 'with CRF', f1_sequence[1]])\n",
        "t.add_row(['Model_7', 'without CRF', f1_sequence[6]])\n",
        "\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------------------+--------------------+\n",
            "|   Model    | with/without CRF |      F1 Score      |\n",
            "+------------+------------------+--------------------+\n",
            "| base model |     with CRF     | 0.7814615945746894 |\n",
            "|  Model_2   |     with CRF     | 0.7715082808132664 |\n",
            "|  Model_7   |   without CRF    | 0.604936071899939  |\n",
            "+------------+------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}